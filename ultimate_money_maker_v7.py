#!/usr/bin/env python3
"""
áŒ€áˆáŠ“á‹­ áˆá‹´áˆá‰½ á‰°áŒˆáŠáŠá‰µ áˆ™áŠ¨áˆ« áˆµáŠ­áˆªá•á‰µ
á‹­áˆ… áˆµáŠ­áˆªá•á‰µ áˆˆ2026 á‹¨á‰°á‹˜áˆ˜áŠ‘ áŒáŒáˆ áŒ€áˆáŠ“á‹­ áˆá‹´áˆá‰½áŠ• á‰°áŒˆáŠáŠá‰µ á‹­áˆáŠ­áˆ«áˆ
"""

import os
import sys
import time
import json
import logging
from typing import List, Dict, Optional, Tuple
from dataclasses import dataclass, asdict
from datetime import datetime
from enum import Enum

# áŒáŒáˆ áŒ€áŠáˆ¬á‰²á‰­ AI áˆ‹á‹­á‰¥áˆ¨áˆª áŠ áˆµáˆáˆ‹áŒŠ áŠá‹
try:
    import google.generativeai as genai
    from google.api_core import exceptions, retry
    GEMINI_AVAILABLE = True
except ImportError:
    GEMINI_AVAILABLE = False
    print("áˆ›áˆµáŒ áŠ•á‰€á‰‚á‹«: google-generativeai áˆ‹á‹­á‰¥áˆ¨áˆª áŠ áˆá‰°áŒ«áŠáˆ")
    print("áŠ¥á‰£áŠ­á‹áŠ• á‹­áŒ«áŠ‘á‰µ: pip install google-generativeai")

# á‹¨áˆáŒ áˆ›á‹‹á‰€áˆ­
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s',
    handlers=[
        logging.FileHandler('gemini_test.log', encoding='utf-8'),
        logging.StreamHandler(sys.stdout)
    ]
)
logger = logging.getLogger(__name__)

class ModelStatus(Enum):
    """áˆá‹´áˆ áˆáŠ”á‰³ áŠ á‹­áŠá‰¶á‰½"""
    AVAILABLE = "áˆŠáŒ á‰€áˆ á‹­á‰½áˆ‹áˆ"
    UNAVAILABLE = "áŠ á‹­áŒˆáŠáˆ"
    LIMITED = "á‹¨á‰°áŒˆá‹°á‰ "
    ERROR = "áˆµáˆ…á‰°á‰µ"
    RATE_LIMITED = "á‹¨ááŒ¥áŠá‰µ áŒˆá‹°á‰¥"

@dataclass
class ModelTestResult:
    """á‹¨áˆá‹´áˆ áˆ™áŠ¨áˆ« á‹áŒ¤á‰µ"""
    model_name: str
    status: ModelStatus
    response_time: float
    capabilities: Dict[str, bool]
    error_message: Optional[str] = None
    timestamp: str = None
    
    def __post_init__(self):
        if self.timestamp is None:
            self.timestamp = datetime.now().isoformat()

class GeminiModelTester:
    """áŒ€áˆáŠ“á‹­ áˆá‹´áˆá‰½áŠ• á‹¨áˆšáˆáŠ­áˆ­ áŠ­ááˆ"""
    
    def __init__(self, api_key: Optional[str] = None):
        """
        áŠ¢áŠ’áˆ»áˆ‹á‹­á‹ áˆ›á‹µáˆ¨áŒ
        
        Args:
            api_key: áŒáŒáˆ AI API á‰áˆá (á‰£á‹­áˆ°áŒ¥ áŠ¨á‰°áˆˆá‹‹á‹‹áŒ­ áŠ áŠ«á‰£á‰¢ á‹­á‹ˆáˆ°á‹³áˆ)
        """
        if not GEMINI_AVAILABLE:
            raise ImportError("google-generativeai áˆ‹á‹­á‰¥áˆ¨áˆª áŠ áˆá‰°áŒ«áŠáˆ")
        
        self.api_key = api_key or os.getenv('GOOGLE_API_KEY')
        if not self.api_key:
            logger.error("API á‰áˆá áŠ áˆá‰°áŒˆáŠ˜áˆá¢ GOOGLE_API_KEY áŠ áŠ•á‰¥á‰ á‹ á‹«áˆµáŒˆá‰¡á‰µá¢")
            sys.exit(1)
        
        # áŒ‚áŠáˆ«á‰²á‰­ AI áŠ®áŠ•áŠáŒ
        genai.configure(api_key=self.api_key)
        
        # áˆˆ2026 á‹¨á‰°á‹˜áˆ˜áŠ‘ áˆá‹´áˆá‰½
        self.models_to_test = [
            {
                'name': 'gemini-3-flash',
                'display_name': 'áŒ€áˆáŠ“á‹­ 3 ááˆ‹áˆ½',
                'description': 'áˆáŒ£áŠ• áŠ¥áŠ“ á‰€áˆ‹áˆ á‰°áŒá‰£áˆ«á‰µ áˆˆáˆšáˆ°áˆ© áˆá‹´áˆ',
                'priority': 1
            },
            {
                'name': 'gemini-3-pro',
                'display_name': 'áŒ€áˆáŠ“á‹­ 3 á•áˆ®',
                'description': 'áˆˆáŠ á‰¥á‹›áŠ›á‹á‰¹ áˆµáˆ«á‹á‰½ á‹¨á‰°áˆ˜á‰»á‰¸ áˆá‹´áˆ',
                'priority': 2
            },
            {
                'name': 'gemini-3-ultra',
                'display_name': 'áŒ€áˆáŠ“á‹­ 3 áŠ¡áˆá‰µáˆ«',
                'description': 'áˆˆáˆ™á‹«á‹Š áŠ¥áŠ“ á‹¨áˆáˆ­áˆáˆ­ á‹°áˆ¨áŒƒ áˆµáˆ«á‹á‰½',
                'priority': 3
            },
            {
                'name': 'gemini-3-flash-lite',
                'display_name': 'áŒ€áˆáŠ“á‹­ 3 ááˆ‹áˆ½ áˆ‹á‹­á‰µ',
                'description': 'áˆˆáˆá‰£á‹­áˆ áŠ¥áŠ“ áŠƒá‹­áˆ á‰†áŒ£á‰¢ áˆ˜áˆ³áˆªá‹«á‹á‰½',
                'priority': 4
            },
            {
                'name': 'gemini-2.5-pro',
                'display_name': 'áŒ€áˆáŠ“á‹­ 2.5 á•áˆ®',
                'description': 'áˆˆá‰°á‹ˆáˆ°áŠ‘ áˆá‹© á‰°áŒá‰£áˆ«á‰µ',
                'priority': 5
            },
            {
                'name': 'gemini-2.0-flash-exp',
                'display_name': 'áŒ€áˆáŠ“á‹­ 2.0 ááˆ‹áˆ½ áŠ¤áŠ­áˆµá”áˆªáˆ˜áŠ•á‰³áˆ',
                'description': 'áˆˆáˆ™áŠ¨áˆ« áŠ¥áŠ“ áˆáˆ­áˆáˆ­',
                'priority': 6
            },
            {
                'name': 'gemini-1.5-flash',
                'display_name': 'áŒ€áˆáŠ“á‹­ 1.5 ááˆ‹áˆ½',
                'description': 'áˆ˜áˆ áˆ¨á‰³á‹Š áˆáŒ£áŠ• áˆá‹´áˆ (áˆ˜á‹°áŒˆáŠá‹«)',
                'priority': 7
            },
            {
                'name': 'gemini-1.5-pro',
                'display_name': 'áŒ€áˆáŠ“á‹­ 1.5 á•áˆ®',
                'description': 'áˆ˜áˆ áˆ¨á‰³á‹Š á•áˆ® áˆá‹´áˆ (áˆ˜á‹°áŒˆáŠá‹«)',
                'priority': 8
            }
        ]
        
        self.available_models = []
        self.test_results = []
        self.recommended_model = None
        
    def _test_single_model(self, model_name: str, test_prompt: str = "áˆ°áˆ‹áˆá¢ áŠ áŒ­áˆ­ áˆáˆ‹áˆ½ áˆµáŒ¥") -> ModelTestResult:
        """
        áŠ áŠ•á‹µ áˆá‹´áˆ á‰°áŒˆáŠáŠá‰µ áˆ™áŠ¨áˆ«
        
        Args:
            model_name: á‹¨áˆšáˆá‰°áˆ½ áˆá‹´áˆ áˆµáˆ
            test_prompt: áˆˆáˆ™áŠ¨áˆ« á‹¨áˆšáŒ á‰€áˆ áŒ¥á‹«á‰„
        
        Returns:
            ModelTestResult: á‹¨áˆ™áŠ¨áˆ«á‹ á‹áŒ¤á‰µ
        """
        start_time = time.time()
        
        try:
            # áˆá‹´áˆ áˆ˜ááŒ áˆ­
            model = genai.GenerativeModel(model_name)
            
            # á‰€áˆ‹áˆ áŒ¥á‹«á‰„ áˆ‹áŠ­
            response = model.generate_content(
                test_prompt,
                generation_config={
                    'max_output_tokens': 50,
                    'temperature': 0.1
                }
            )
            
            response_time = time.time() - start_time
            
            # á‰½áˆá‰³á‹á‰½áŠ• áˆ›áˆ¨áŒ‹áŒˆáŒ«
            capabilities = {
                'text_generation': bool(response.text),
                'fast_response': response_time < 2.0,
                'reliable': True
            }
            
            return ModelTestResult(
                model_name=model_name,
                status=ModelStatus.AVAILABLE,
                response_time=response_time,
                capabilities=capabilities
            )
            
        except exceptions.NotFound as e:
            logger.warning(f"áˆá‹´áˆ {model_name} áŠ áˆá‰°áŒˆáŠ˜áˆ: {e}")
            return ModelTestResult(
                model_name=model_name,
                status=ModelStatus.UNAVAILABLE,
                response_time=time.time() - start_time,
                capabilities={},
                error_message=str(e)
            )
            
        except exceptions.ResourceExhausted as e:
            logger.warning(f"áˆá‹´áˆ {model_name} áˆ‹á‹­ á‹¨ááŒ¥áŠá‰µ áŒˆá‹°á‰¥: {e}")
            return ModelTestResult(
                model_name=model_name,
                status=ModelStatus.RATE_LIMITED,
                response_time=time.time() - start_time,
                capabilities={},
                error_message=str(e)
            )
            
        except Exception as e:
            logger.error(f"áˆá‹´áˆ {model_name} áˆ‹á‹­ áˆµáˆ…á‰°á‰µ: {e}")
            return ModelTestResult(
                model_name=model_name,
                status=ModelStatus.ERROR,
                response_time=time.time() - start_time,
                capabilities={},
                error_message=str(e)
            )
    
    @retry.Retry(
        predicate=retry.if_exception_type(
            exceptions.ResourceExhausted,
            exceptions.ServiceUnavailable
        ),
        maximum=3,
        deadline=30
    )
    def test_all_models(self) -> List[ModelTestResult]:
        """
        áˆáˆ‰áŠ•áˆ áˆá‹´áˆá‰½ á‹­áˆáŠ­áˆ­
        
        Returns:
            á‹¨áˆáˆ‰áˆ áˆ™áŠ¨áˆ«á‹á‰½ á‹áŒ¤á‰µ
        """
        logger.info("á‹¨áŒ€áˆáŠ“á‹­ áˆá‹´áˆá‰½ á‰°áŒˆáŠáŠá‰µ áˆ™áŠ¨áˆ« áŠ¥á‹¨áŒ€áˆ˜áˆ¨ áŠá‹...")
        
        test_results = []
        
        # á‰ á‰…á‹µáˆšá‹« á‹°áˆ¨áŒƒ á‹¨á‰°á‹°áˆ¨á‹°áˆ© áˆá‹´áˆá‰½áŠ• áˆ˜áˆáŠ¨áˆ­
        sorted_models = sorted(self.models_to_test, key=lambda x: x['priority'])
        
        for model_info in sorted_models:
            model_name = model_info['name']
            display_name = model_info['display_name']
            
            logger.info(f"áˆá‹´áˆáŠ• áŠ¥á‹¨áˆá‰°áˆ½áŠ• áŠá‹: {display_name} ({model_name})")
            
            # áˆá‹´áˆ áˆ™áŠ¨áˆ«
            result = self._test_single_model(model_name)
            test_results.append(result)
            
            # á‹¨áˆšáŒ á‰€áˆ áŠ¨áˆ†áŠ á‹áˆ­á‹áˆ­ á‹áˆµáŒ¥ áˆ›áŠ–áˆ­
            if result.status == ModelStatus.AVAILABLE:
                self.available_models.append({
                    'name': model_name,
                    'display_name': display_name,
                    'description': model_info['description'],
                    'response_time': result.response_time,
                    'priority': model_info['priority']
                })
            
            # áŠ áŒ­áˆ­ áŠ¥áˆ¨áá‰µ áˆˆáˆ˜á‹áˆ°á‹µ
            time.sleep(0.5)
        
        self.test_results = test_results
        self._determine_recommended_model()
        
        return test_results
    
    def _determine_recommended_model(self):
        """áˆáŠ­áˆ¨ áˆá‹´áˆ áˆ˜á‹ˆáˆ°áŠ•"""
        if not self.available_models:
            self.recommended_model = None
            return
        
        # á‰ ááŒ¥áŠá‰µ áŠ¥áŠ“ á‰ á‰…á‹µáˆšá‹« á‹°áˆ¨áŒƒ áˆ˜áˆ áˆ¨á‰µ áˆ˜á‹°áˆ­á‹°áˆ­
        sorted_available = sorted(
            self.available_models,
            key=lambda x: (x['response_time'], x['priority'])
        )
        
        self.recommended_model = sorted_available[0]
    
    def generate_report(self, output_format: str = "text") -> str:
        """
        á‹¨áˆ™áŠ¨áˆ« áˆªá–áˆ­á‰µ áˆ›á‹˜áŒ‹áŒ€á‰µ
        
        Args:
            output_format: á‹¨á‹áŒ¤á‰µ á‰…áˆ­áŒ¸á‰µ (text, json, html)
        
        Returns:
            á‹¨á‰°á‹˜áŒ‹áŒ€ áˆªá–áˆ­á‰µ
        """
        if not self.test_results:
            return "áˆáŠ•áˆ á‹¨áˆ™áŠ¨áˆ« á‹áŒ¤á‰µ á‹¨áˆˆáˆá¢ á‰ áˆ˜áŒ€áˆ˜áˆªá‹« test_all_models() á‹­áŒ¥áˆ©á¢"
        
        if output_format == "json":
            return self._generate_json_report()
        elif output_format == "html":
            return self._generate_html_report()
        else:
            return self._generate_text_report()
    
    def _generate_text_report(self) -> str:
        """áŒ½áˆ‘á áˆªá–áˆ­á‰µ áˆ›á‹˜áŒ‹áŒ€á‰µ"""
        report_lines = []
        
        # áˆ«áŠ¥á‹­ áˆ˜áŒá‰¢á‹«
        report_lines.append("=" * 60)
        report_lines.append("á‹¨áŒ€áˆáŠ“á‹­ áˆá‹´áˆá‰½ á‰°áŒˆáŠáŠá‰µ áˆ™áŠ¨áˆ« áˆªá–áˆ­á‰µ")
        report_lines.append(f"áŒŠá‹œ: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
        report_lines.append("=" * 60)
        report_lines.append("")
        
        # áˆ›áŒ á‰ƒáˆˆá‹«
        available_count = sum(1 for r in self.test_results if r.status == ModelStatus.AVAILABLE)
        total_count = len(self.test_results)
        
        report_lines.append(f"áˆ›áŒ á‰ƒáˆˆá‹«:")
        report_lines.append(f"  - áŠ áŒ á‰ƒáˆ‹á‹­ á‹¨á‰°áˆáŠ¨áˆ© áˆá‹´áˆá‰½: {total_count}")
        report_lines.append(f"  - á‹¨áˆšáŒ á‰€áˆ™ áˆá‹´áˆá‰½: {available_count}")
        report_lines.append(f"  - á‹¨áˆ›á‹­áŒ á‰€áˆ™ áˆá‹´áˆá‰½: {total_count - available_count}")
        report_lines.append("")
        
        # á‹¨áˆšáˆ˜áŠ¨áˆ­ áˆá‹´áˆ
        if self.recommended_model:
            report_lines.append(f"á‹¨áˆšáˆ˜áŠ¨áˆ­ áˆá‹´áˆ:")
            report_lines.append(f"  - áˆµáˆ: {self.recommended_model['display_name']}")
            report_lines.append(f"  - áŠ®á‹µ: {self.recommended_model['name']}")
            report_lines.append(f"  - á‹¨áˆáˆ‹áˆ½ áŒŠá‹œ: {self.recommended_model['response_time']:.2f} áˆ°áŠ¨áŠ•á‹µ")
            report_lines.append(f"  - áˆ˜áŒáˆˆáŒ«: {self.recommended_model['description']}")
            report_lines.append("")
        
        # á‹áˆ­á‹áˆ­ á‹áŒ¤á‰¶á‰½
        report_lines.append("á‹áˆ­á‹áˆ­ á‹áŒ¤á‰¶á‰½:")
        report_lines.append("-" * 60)
        
        for result in self.test_results:
            status_icon = "âœ…" if result.status == ModelStatus.AVAILABLE else "âŒ"
            
            report_lines.append(f"{status_icon} {result.model_name}")
            report_lines.append(f"  áˆáŠ”á‰³: {result.status.value}")
            
            if result.response_time > 0:
                report_lines.append(f"  á‹¨áˆáˆ‹áˆ½ áŒŠá‹œ: {result.response_time:.2f} áˆ°áŠ¨áŠ•á‹µ")
            
            if result.error_message:
                report_lines.append(f"  áˆµáˆ…á‰°á‰µ: {result.error_message[:100]}...")
            
            report_lines.append("")
        
        # á‹¨áˆ˜áŒ á‰€áˆ áˆáŠ­áˆ­
        report_lines.append("=" * 60)
        report_lines.append("á‹¨áˆ˜áŒ á‰€áˆ áˆáŠ­áˆ­:")
        
        if self.available_models:
            report_lines.append("1. áˆˆáˆáŒ£áŠ• áˆµáˆ«á‹á‰½: gemini-3-flash á‹­áŒ á‰€áˆ™")
            report_lines.append("2. áˆˆáŠ áŒ á‰ƒáˆ‹á‹­ áˆµáˆ«á‹á‰½: gemini-3-pro á‹­áŒ á‰€áˆ™")
            report_lines.append("3. áˆˆáˆ™á‹«á‹Š áˆµáˆ«á‹á‰½: gemini-3-ultra á‹­áŒ á‰€áˆ™")
            report_lines.append("4. áˆˆáˆá‰£á‹­áˆ áˆ˜á‰°áŒá‰ áˆªá‹«á‹á‰½: gemini-3-flash-lite á‹­áŒ á‰€áˆ™")
        else:
            report_lines.append("áˆáŠ•áˆ á‹¨áˆšáŒ á‰€áˆ áˆá‹´áˆ áŠ áˆá‰°áŒˆáŠ˜áˆá¢")
            report_lines.append("áŠ¥á‰£áŠ­á‹áŠ• á‹¨API á‰áˆáá‹áŠ• á‹«áˆ¨áŒ‹áŒáŒ¡á¢")
        
        report_lines.append("=" * 60)
        
        return "\n".join(report_lines)
    
    def _generate_json_report(self) -> str:
        """JSON áˆªá–áˆ­á‰µ áˆ›á‹˜áŒ‹áŒ€á‰µ"""
        report_data = {
            'timestamp': datetime.now().isoformat(),
            'summary': {
                'total_tested': len(self.test_results),
                'available': len(self.available_models),
                'unavailable': len(self.test_results) - len(self.available_models)
            },
            'recommended_model': self.recommended_model,
            'available_models': self.available_models,
            'test_results': [asdict(r) for r in self.test_results]
        }
        
        return json.dumps(report_data, ensure_ascii=False, indent=2)
    
    def _generate_html_report(self) -> str:
        """HTML áˆªá–áˆ­á‰µ áˆ›á‹˜áŒ‹áŒ€á‰µ"""
        html = f"""
        <!DOCTYPE html>
        <html lang="am">
        <head>
            <meta charset="UTF-8">
            <meta name="viewport" content="width=device-width, initial-scale=1.0">
            <title>á‹¨áŒ€áˆáŠ“á‹­ áˆá‹´áˆá‰½ áˆ™áŠ¨áˆ« áˆªá–áˆ­á‰µ</title>
            <style>
                body {{ font-family: 'Arial', sans-serif; line-height: 1.6; margin: 20px; }}
                .header {{ background-color: #4285f4; color: white; padding: 20px; border-radius: 5px; }}
                .summary {{ background-color: #f1f8ff; padding: 15px; border-radius: 5px; margin: 20px 0; }}
                .model-card {{ border: 1px solid #ddd; border-radius: 5px; padding: 15px; margin: 10px 0; }}
                .available {{ border-left: 5px solid #34a853; }}
                .unavailable {{ border-left: 5px solid #ea4335; }}
                .recommended {{ background-color: #e8f5e9; border: 2px solid #34a853; }}
            </style>
        </head>
        <body>
            <div class="header">
                <h1>á‹¨áŒ€áˆáŠ“á‹­ áˆá‹´áˆá‰½ á‰°áŒˆáŠáŠá‰µ áˆ™áŠ¨áˆ« áˆªá–áˆ­á‰µ</h1>
                <p>áŒŠá‹œ: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}</p>
            </div>
            
            <div class="summary">
                <h2>áˆ›áŒ á‰ƒáˆˆá‹«</h2>
                <p>áŠ áŒ á‰ƒáˆ‹á‹­ á‹¨á‰°áˆáŠ¨áˆ© áˆá‹´áˆá‰½: {len(self.test_results)}</p>
                <p>á‹¨áˆšáŒ á‰€áˆ™ áˆá‹´áˆá‰½: {len(self.available_models)}</p>
                <p>á‹¨áˆ›á‹­áŒ á‰€áˆ™ áˆá‹´áˆá‰½: {len(self.test_results) - len(self.available_models)}</p>
            </div>
        """
        
        if self.recommended_model:
            html += f"""
            <div class="model-card recommended">
                <h3>ğŸŒŸ á‹¨áˆšáˆ˜áŠ¨áˆ­ áˆá‹´áˆ</h3>
                <p><strong>{self.recommended_model['display_name']}</strong> ({self.recommended_model['name']})</p>
                <p>á‹¨áˆáˆ‹áˆ½ áŒŠá‹œ: {self.recommended_model['response_time']:.2f} áˆ°áŠ¨áŠ•á‹µ</p>
                <p>{self.recommended_model['description']}</p>
            </div>
            """
        
        html += "<h2>á‹¨áˆá‹´áˆ áˆ™áŠ¨áˆ« á‹áŒ¤á‰¶á‰½</h2>"
        
        for result in self.test_results:
            status_class = "available" if result.status == ModelStatus.AVAILABLE else "unavailable"
            
            html += f"""
            <div class="model-card {status_class}">
                <h3>{result.model_name}</h3>
                <p><strong>áˆáŠ”á‰³:</strong> {result.status.value}</p>
                <p><strong>á‹¨áˆáˆ‹áˆ½ áŒŠá‹œ:</strong> {result.response_time:.2f} áˆ°áŠ¨áŠ•á‹µ</p>
            """
            
            if result.error_message:
                html += f'<p><strong>áˆµáˆ…á‰°á‰µ:</strong> {result.error_message[:100]}...</p>'
            
            html += "</div>"
        
        html += """
            <footer>
                <p>Â© 2026 á‹¨áŒ€áˆáŠ“á‹­ áˆá‹´áˆ áˆ™áŠ¨áˆ« áˆ˜áˆ£áˆªá‹«</p>
            </footer>
        </body>
        </html>
        """
        
        return html
    
    def save_report(self, filename: str = "gemini_models_report"):
        """
        áˆªá–áˆ­á‰µ áˆˆáˆ›áˆµá‰€áˆ˜áŒ¥
        
        Args:
            filename: á‹¨á‹á‹­áˆ áˆµáˆ (á‰…áŒ¥á‹« áŠ á‹­áŒ¨áˆ˜áˆ­áˆ)
        """
        # áŒ½áˆ‘á áˆªá–áˆ­á‰µ
        text_report = self.generate_report("text")
        with open(f"{filename}.txt", 'w', encoding='utf-8') as f:
            f.write(text_report)
        
        # JSON áˆªá–áˆ­á‰µ
        json_report = self.generate_report("json")
        with open(f"{filename}.json", 'w', encoding='utf-8') as f:
            f.write(json_report)
        
        # HTML áˆªá–áˆ­á‰µ
        html_report = self.generate_report("html")
        with open(f"{filename}.html", 'w', encoding='utf-8') as f:
            f.write(html_report)
        
        logger.info(f"áˆªá–áˆ­á‰¶á‰½ á‰°áˆ°á‰¥áˆµá‰ á‹‹áˆ: {filename}.txt, {filename}.json, {filename}.html")
    
    def get_available_models(self) -> List[str]:
        """
        á‹¨áˆšáŒ á‰€áˆ™ áˆá‹´áˆá‰½ á‹áˆ­á‹áˆ­ áˆ˜áˆ˜áˆˆáˆµ
        
        Returns:
            á‹¨áˆšáŒ á‰€áˆ™ áˆá‹´áˆá‰½ á‹áˆ­á‹áˆ­
        """
        return [model['name'] for model in self.available_models]
    
    def get_best_model(self, use_case: str = "general") -> Optional[str]:
        """
        áˆˆá‰°á‹ˆáˆ°áŠ áŒ¥á‰…áˆ á‹¨áˆšáˆ˜áŠ¨áˆ­ áˆá‹´áˆ
        
        Args:
            use_case: á‹¨áˆ˜áŒ á‰€áˆ áŠ á‹­áŠá‰µ (general, fast, professional, mobile)
        
        Returns:
            á‹¨áˆšáˆ˜áŠ¨áˆ­ áˆá‹´áˆ áˆµáˆ
        """
        if not self.available_models:
            return None
        
        use_case_map = {
            'general': ['gemini-3-pro', 'gemini-1.5-pro'],
            'fast': ['gemini-3-flash', 'gemini-1.5-flash'],
            'professional': ['gemini-3-ultra', 'gemini-3-pro'],
            'mobile': ['gemini-3-flash-lite', 'gemini-3-flash'],
            'fallback': ['gemini-1.5-pro', 'gemini-1.5-flash']
        }
        
        preferred_models = use_case_map.get(use_case, use_case_map['general'])
        
        for model_name in preferred_models:
            for available in self.available_models:
                if available['name'] == model_name:
                    return model_name
        
        # áˆáŠ•áˆ áŠ¨á‰°áˆ˜áˆ¨áŒ¡á‰µ á‹áˆ­á‹áˆ­ áŠ«áˆá‰°áŒˆáŠ˜ á‹¨áˆ˜áŒ€áˆ˜áˆªá‹«á‹áŠ• á‹¨áˆšáŒ á‰€áˆ áˆá‹´áˆ áˆ˜áˆáˆµ
        return self.available_models[0]['name'] if self.available_models else None


# á‰€áˆ‹áˆ á‹¨áˆ˜áŒ á‰€áˆ áˆáˆ³áˆŒ
def main():
    """á‹‹áŠ“ á‹¨áˆ˜áŒá‰¢á‹« áŠáŒ¥á‰¥"""
    print("á‹¨áŒ€áˆáŠ“á‹­ áˆá‹´áˆá‰½ á‰°áŒˆáŠáŠá‰µ áˆ™áŠ¨áˆ« áˆ˜áˆ£áˆªá‹«")
    print("-" * 50)
    
    if not GEMINI_AVAILABLE:
        print("áŠ¥á‰£áŠ­á‹áŠ• á‰ áˆ˜áŒ€áˆ˜áˆªá‹« áŠ áˆµáˆáˆ‹áŒŠ áˆ‹á‹­á‰¥áˆ¨áˆªá‹á‰½áŠ• á‹­áŒ«áŠ‘:")
        print("pip install google-generativeai")
        return
    
    # API á‰áˆá áˆ›áˆ¨áŒ‹áŒˆáŒ«
    api_key = os.getenv('GOOGLE_API_KEY')
    if not api_key:
        print("GOOGLE_API_KEY áŠ áˆá‰°áŒˆáŠ˜áˆá¢")
        print("áŠ¥á‰£áŠ­á‹áŠ• áŠ¥áŠ•á‹²áˆ… á‹«áˆµáŒˆá‰¡á‰µ:")
        print("export GOOGLE_API_KEY='your_api_key_here'")
        print("á‹ˆá‹­áˆ á‰ á‰€áŒ¥á‰³ á‹«áˆµáŒˆá‰¡:")
        api_key = input("á‹¨áŒáŒáˆ API á‰áˆáá‹áŠ• á‹«áˆµáŒˆá‰¡: ").strip()
    
    try:
        # á‰´áˆµá‰°áˆ­ áˆ˜ááŒ áˆ­
        tester = GeminiModelTester(api_key)
        
        print("áˆá‹´áˆá‰½áŠ• áŠ¥á‹¨áˆá‰°áˆ½áŠ• áŠá‹... áŠ¥áˆ­áˆá‰µ á‹«á‹µáˆ­áŒ‰á¢")
        print()
        
        # áˆáˆ‰áŠ•áˆ áˆá‹´áˆá‰½ áˆ˜áˆáŠ¨áˆ­
        results = tester.test_all_models()
        
        # áˆªá–áˆ­á‰µ áˆ›áˆ³á‹¨á‰µ
        report = tester.generate_report("text")
        print(report)
        
        # áˆªá–áˆ­á‰¶á‰½áŠ• áˆ›áˆµá‰€áˆ˜áŒ¥
        save_option = input("áˆªá–áˆ­á‰¶á‰½áŠ• áˆ›áˆµá‰€áˆ˜áŒ¥ á‹­áˆáˆáŒ‹áˆ‰? (áŠ á‹/áŠ á‹­): ").lower()
        if save_option in ['áŠ á‹', 'y', 'yes', 'ááˆ', 'áˆ']:
            tester.save_report()
            print("áˆªá–áˆ­á‰¶á‰½ á‰°áˆ°á‰¥áˆµá‰ á‹‹áˆ!")
        
        # á‹¨áˆšáŒ á‰€áˆ™ áˆá‹´áˆá‰½ á‹áˆ­á‹áˆ­
        available = tester.get_available_models()
        if available:
            print("\ná‹¨áˆšáŒ á‰€áˆ™ áˆá‹´áˆá‰½:")
            for model in available:
                print(f"  - {model}")
            
            # áˆˆá‰°áˆˆá‹«á‹© á‹“áˆ‹áˆ›á‹á‰½ áˆáŠ­áˆ­
            print("\náˆˆá‰°áˆˆá‹«á‹© á‹“áˆ‹áˆ›á‹á‰½ áˆáŠ­áˆ­:")
            for use_case in ['general', 'fast', 'professional', 'mobile']:
                best_model = tester.get_best_model(use_case)
                if best_model:
                    print(f"  áˆˆ{use_case}: {best_model}")
        
    except Exception as e:
        print(f"áˆµáˆ…á‰°á‰µ á‰°áŠ¨áˆµá‰·áˆ: {e}")
        logger.exception("á‹‹áŠ“á‹ á‰°áŒá‰£áˆ­ áˆ‹á‹­ áˆµáˆ…á‰°á‰µ")


if __name__ == "__main__":
    main()
